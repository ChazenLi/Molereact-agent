# -*- coding: utf-8 -*-
"""
Module: multistep.agent.agent_run
Called By: User (CLI Main Entry)
Role: Workflow Orchestrator / User Interaction Handler

Functionality:
    Orchestrates the complete 5-step retrosynthesis workflow:
    1. Generation (RetroSingleStep)
    2. Analysis (MoleculeAnalysis)
    3. Inventory Check (StockCheck)
    4. Planning (LLM/Heuristic Selection)
    5. Visualization (StageVisualization)

    Manages the "Agentic Loop" including:
    - Task Queue Management (Global Unsolved Queue)
    - User Interaction (CLI: Selection, Switch, Verify)
    - Session Logging and Report Generation
    
Key Classes:
    - CompleteWorkModuleRunner: Main controller class.

Features:
    - Integration of new `tools` package (RDKit, Inventory).
    - ReAct Loop Interface for dynamic analysis.
    - Robust Error Handling and Resume capability.

Usage:
    python agent/agent_run.py --auto
    python agent/agent_run.py --smiles "TargetSMILES"
"""

import sys
import os
import argparse
import logging
import json
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple

# Setup path (MUST BE BEFORE IMPORTS)
import os
_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
_MULTISTEP_DIR = os.path.dirname(_SCRIPT_DIR)
_MOLEREACT_ROOT = os.path.dirname(_MULTISTEP_DIR)

if _MOLEREACT_ROOT not in sys.path:
    sys.path.insert(0, _MOLEREACT_ROOT)
if _MULTISTEP_DIR not in sys.path:
    # Also add parent dir for fallback
    sys.path.insert(0, _MULTISTEP_DIR)

try:
    from multistep.agent.config import AgentConfig, InteractionMode, AgentMode
    from multistep.agent.agent_react import ReActRetroAgent
    from multistep.agent.tools.visualization import VisualizationTool
except ImportError:
    from config import AgentConfig, InteractionMode, AgentMode
    from agent_react import ReActRetroAgent
    from tools.visualization import VisualizationTool
from dataclasses import dataclass, asdict


try:
    from multistep.agent.session_logger import SessionLogger
    from multistep.agent.prompts import get_system_role_prompt, get_selection_v2_prompt, get_smiles_repair_prompt
    from multistep.agent.smiles_standardizer import Standardizer
    from multistep.agent.tools.analysis import MoleculeAnalysisTool
    from multistep.agent.core.react import ReActSession
except ImportError:
    sys.path.append(os.path.join(_MULTISTEP_DIR, "agent"))
    from session_logger import SessionLogger
    from prompts import get_system_role_prompt, get_selection_v2_prompt, get_smiles_repair_prompt
    from smiles_standardizer import Standardizer
    from tools.analysis import MoleculeAnalysisTool
    from tools.advanced_analysis import toolbox as advanced_toolbox
    from core.react import ReActSession

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)

# é»˜è®¤æµ‹è¯•åˆ†å­
DEFAULT_TARGET = "FC1=CC=C(C=C1)[C@H](CN2C=NC3=C2C=CN3C4=CC=C(C=C4)N5CCN(C5)C6=CC(=NC=N6)C7=CN(C=N7)C)N"

ZHIPUAI_API_KEY = os.environ.get("ZHIPUAI_API_KEY", "fe03944e939a4cd08084203ab88ccf8d.wF2T0LQjxkwR0lJv")
CHATGLM_MODEL = "glm-4.7"  # ä½¿ç”¨æœ€æ–°æ¨¡å‹ï¼Œæ”¯æŒæ·±åº¦æ€è€ƒ

# V2.2: åœºæ™¯è¯„åˆ†æƒé‡é…ç½®
SCENARIO_PROFILES = {
    "ACADEMIC": {
        "complexity": 0.4, "reactivity": 0.3, "selectivity": 0.3, "efficiency": 0.0, "pg_cost": 0.0
    },
    "INDUSTRIAL": {
        "complexity": 0.15, "reactivity": 0.15, "selectivity": 0.2, "efficiency": 0.25, "pg_cost": 0.25
    }
}
# é»˜è®¤ä¸ºå·¥ä¸šæ¨¡å¼
CURRENT_SCENARIO = "INDUSTRIAL"


@dataclass
class StageResult:
    """é˜¶æ®µç»“æœ"""
    stage: int
    target_smiles: str
    model_candidates: List[Dict]
    template_candidates: List[Dict]
    stock_results: Dict
    llm_selected_top_n: List[Dict]
    unsolved_leaves: List[str]
    is_complete: bool
    llm_analysis: str
    timestamp: str
    image_paths: List[str] = None  # å¯è§†åŒ–å›¾ç‰‡è·¯å¾„åˆ—è¡¨

    def to_dict(self):
        return asdict(self)


class CompleteWorkModuleRunner:
    """å®Œæ•´å·¥ä½œæ¨¡å—è¿è¡Œå™¨"""
    
    def __init__(self, use_llm: bool = True, auto_mode: bool = False):
        self.use_llm = use_llm
        self.auto_mode = auto_mode
        self.engine = None
        self.standardizer = Standardizer()
        self.analyzer = MoleculeAnalysisTool()
        self.llm_client = None
        self.history: List[StageResult] = []
        self.output_dir = os.path.join(_MULTISTEP_DIR, "output", "agent_runs")
        os.makedirs(self.output_dir, exist_ok=True)
        self.session_logger = SessionLogger(self.output_dir)
        print(f"ğŸ“„ Session Log: {self.session_logger.log_path}")
        self.stock_cache = {} # Cache for SMILES -> stock_status
        # self.visited_smiles = set() # æ—§ç‰ˆ: å…¨å±€å»é‡ (å¼ƒç”¨)
        # self.lineage_map = {} # æ–°ç‰ˆ: åŸºäºè·¯å¾„çš„è°±ç³»è·Ÿè¸ª
        
    def initialize(self):
        """åˆå§‹åŒ–å¼•æ“å’Œ LLM å®¢æˆ·ç«¯"""
        print("\n" + "=" * 70)
        print(" åˆå§‹åŒ– Agent å·¥ä½œæ¨¡å—")
        print("=" * 70)
        
        # åŠ è½½é€†åˆæˆå¼•æ“
        print("\nğŸ“¦ åŠ è½½é€†åˆæˆå¼•æ“...")
        from multistep.single_step_engine import create_default_engine
        self.engine = create_default_engine()
        print("âœ… å¼•æ“åŠ è½½å®Œæˆ")
        
        # åˆå§‹åŒ– LLM å®¢æˆ·ç«¯ (ä½¿ç”¨æ–°ç‰ˆ zai SDK)
        if self.use_llm:
            print("\n åˆå§‹åŒ– LLM å®¢æˆ·ç«¯ (ZhipuAI)...")
            try:
                try:
                    from zai import ZhipuAiClient
                    self.llm_client = ZhipuAiClient(api_key=ZHIPUAI_API_KEY)
                    print("âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (glm-4.7 æ·±åº¦æ€è€ƒæ¨¡å¼)")
                except ImportError:
                    print("âš ï¸ zai æœªå®‰è£…ï¼Œå°è¯•æ—§ç‰ˆ zhipuai...")
                    try:
                        from zhipuai import ZhipuAI
                        self.llm_client = ZhipuAI(api_key=ZHIPUAI_API_KEY)
                        print("âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (zhipuai å…¼å®¹æ¨¡å¼)")
                    except ImportError:
                        print("âš ï¸ zhipuai ä¹Ÿæœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¯å‘å¼ç­›é€‰")
                        self.llm_client = None
            except Exception as e:
                print(f"âš ï¸ LLM åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å¯å‘å¼ç­›é€‰")
                self.llm_client = None
        
        # Initialize ReAct Agent (Subclass)
        # This allows us to use the encapsulated logic of the new agent
        self.agent = ReActRetroAgent(
            config=AgentConfig.for_research(), # Default config
            engine=self.engine,
            session=None, # Will be lazy loaded
            llm_client=self.llm_client
        )
        print("âœ… ReAct ä»£ç† (Sandbox) å·²æŒ‚è½½")
    
    def run_work_module(self, target_smiles: str, stage: int = 1, topk: int = 10, history_context: str = "", path_id: str = "1") -> StageResult:
        """
        V3.0: Delegate fully to the Autonomous Meta-Controller.
        Replaces the old 5-step linear pipeline.
        """
        if hasattr(self.agent, "run_autonomous_loop"):
            print(f"\nğŸš€ Initiating Autonomous Agent V3.0 Protocol (ID: {path_id})...")
            final_report = self.agent.run_autonomous_loop(target_smiles)
            print(f"\nğŸ Autonomous Loop Finished.\nReport: {final_report}")
            
            # Check if really complete
            is_done = False
            if hasattr(self.agent, "tree") and self.agent.tree:
                is_done = not self.agent.tree.get_open_nodes()
                
            return StageResult(
                stage=stage,
                target_smiles=target_smiles,
                model_candidates=[], template_candidates=[], stock_results={}, 
                llm_selected_top_n=[], unsolved_leaves=[], is_complete=is_done,
                llm_analysis=final_report, timestamp=datetime.now().isoformat()
            )
        else:
            # Fallback if somehow agent is not V3
            return super().run_work_module(target_smiles, stage, topk, history_context, path_id=path_id)
    
    def _llm_select_top_n(
        self,
        target: str,
        candidates: List,
        stock_results: Dict,
        stage: int = 1,
        top_n: int = 7,  # Default increased to 7
        history_context: str = "",
        cumulative_route: Dict = None 
    ) -> Tuple[List[Dict], str]:
        """ä½¿ç”¨ LLM ç­›é€‰ Top-N å¹¶æå‡ºæ–°é¢–è·¯çº¿ (Holistic V2.0)"""
        print("  è°ƒç”¨ ChatGLM æ·±åº¦åˆ†æ...")
        
        # æ„å»º prompt (å®Œæ•´ SMILES)
        stock_map = {r["smiles"]: r["in_stock"] for r in stock_results["results"]}
        
        # æ„å»º Prompt (ä½¿ç”¨ prompts.py æ¨¡å—)
        # é¢„å…ˆæ ¼å¼åŒ–å€™é€‰è·¯çº¿æ–‡æœ¬
        candidate_blocks = []
        for i, cand in enumerate(candidates[:15], 1):
            source = cand.source if hasattr(cand, 'source') else cand.get('source', 'unknown')
            precursors = cand.precursors if hasattr(cand, 'precursors') else cand.get('precursors', [])
            confidence = cand.confidence if hasattr(cand, 'confidence') else cand.get('confidence', 0)
            
            precursor_lines = []
            analysis_report = [] # V2.2: Autonomous Analysis Report
            
            for p in precursors:
                status = "âœ…å¯è´­ä¹°" if stock_map.get(p, False) else "âŒéœ€åˆæˆ"
                precursor_lines.append(f"  - `{p}` ({status})")
                
                # Autonomous Analysis
                try:
                    if self.analyzer:
                        props = self.analyzer.execute(p)
                        # Format compact analysis line
                        # Violations: specific check
                        v_count = props.get('LipinskiViolations', 0)
                        v_str = f"âš ï¸Violations={v_count}" if v_count > 0 else "âœ…Lipinski OK"
                        
                        report_line = (
                            f"     * Analysis for `{p}`: "
                            f"MW={props.get('MolecularWeight', 0):.1f}, "
                            f"LogP={props.get('LogP', 0):.2f}, "
                            f"TPSA={props.get('TPSA', 0):.1f}, "
                            f"{v_str}"
                        )
                        analysis_report.append(report_line)
                except Exception as e:
                    analysis_report.append(f"     * Analysis Error for `{p}`: {str(e)}")

            # --- [NEW] Advanced Analysis Toolbox Integration ---
            try:
                # 1. Run Advanced Analysis (AtomEconomy, ESOL, Bertz, etc.)
                adv_results = advanced_toolbox.analyze_candidate(target, precursors)
                
                # 2. Append to Analysis Report
                if adv_results:
                    analysis_report.append("\n     [Advanced Metrics]")
                    analysis_report.append(f"     {adv_results.get('formatted_report', '')}")
            except Exception as e:
                print(f"Warning: Advanced analysis failed: {e}")
                # analysis_report.append(f"     [Advanced Analysis Failed]: {str(e)}")
            # ---------------------------------------------------

            analysis_block = "\n".join(analysis_report) if analysis_report else "     (No analysis data available)"
            
            # Explicitly mark scores as deprecated/reference only per user request
            block = (
                f"### è·¯çº¿ {i} [{source.upper()}]\n"
                f"   [Comparison]:\n"
                f"       Target   : {target}\n"
                f"       Precursors: {', '.join(precursors)}\n"
                f"   [Internal Scores - IGNORE]: Confidence={confidence:.4f} (Provided for ref only)\n"
                f"   [Precursors List]:\n" + "\n".join(precursor_lines) + "\n"
                f"   [Component Analysis Report - USE THIS]:\n{analysis_block}\n"
            )
            candidate_blocks.append(block)
        
        candidates_text = "\n\n".join(candidate_blocks)
        
        prompt = get_selection_v2_prompt(
            target=target,
            stage=stage,
            candidates_text=candidates_text,
            stock_rate=stock_results['stock_rate'],
            history_context=history_context,
            top_n=top_n
        )
        
        print(f"  ğŸ“ Prompt Length: {len(prompt)} chars")
        
        try:
            print(f"  ğŸ§  Switching to ReAct Selection Mode provided by ReActRetroAgent...")
            
            # Use the ReAct Agent helper directly
            # Note: We pass the constructed candidates_text
            llm_text = self.agent.evaluate_candidates_with_react(
                target=target,
                candidates_text=candidates_text,
                context=history_context,
                criteria="Select Top-N valid routes. Ignore scores if analysis contradicts."
            )
            
            # ReAct returns the final answer string directly
            print(f"\n  ğŸ“ [ReAct ç»“è®º]:\n{llm_text[:200]}...")
            
            # Compatibility: Fake full_response list for downstream logic if needed, 
            # but we define llm_text directly so it's fine.
            full_response = [llm_text] 
            
            # è§£ææ¨è (ä» LLM å“åº”ä¸­æå–)
            # è§£æ Task 1 çš„ç»“æœ
            # Parse JSON Response (V3.4 Agentic Protocol)
            print("\n  ğŸ” Parsing JSON Response...", flush=True)
            
            import re
            import json
            
            results_data = {}
            llm_text = "".join(full_response)
            
            # Robust JSON Parsing Loop (V3.4 Fix)
            max_retries = 2
            last_error = ""
            current_attempt = 0
            
            while current_attempt <= max_retries:
                if current_attempt > 0:
                     print(f"  ğŸ”„ Retry Attempt {current_attempt}/{max_retries} due to JSON error...")
                     # In a real retry loop involving LLM, we would re-call the API here.
                     # However, since agent_full.py calls ReAct (external class) which handles the prompt internally,
                     # we can't easily re-inject the prompt here without refactoring ReAct.evaluate_candidates_with_react.
                     # For now, we will just try to repair the string locally or fail.
                     # But wait! We can't re-call LLM here easily because 'llm_text' is already returned.
                     # The retry loop logic in agent_run.py re-called the API.
                     # Here, we should rely on ReAct to be robust, OR accept that we only parse what we got.
                     # Given the structure, maybe we just improve local cleaning first.
                     pass 

                # Parsing Logic
                json_str = llm_text
                if "```json" in llm_text:
                    match = re.search(r"```json\s*(.*?)\s*```", llm_text, re.DOTALL)
                    if match: json_str = match.group(1)
                elif "```" in llm_text:
                    match = re.search(r"```\s*(.*?)\s*```", llm_text, re.DOTALL)
                    if match: json_str = match.group(1)
                
                try:
                    json_str = json_str.strip()
                    if not json_str.endswith("}"):
                        last_brace = json_str.rfind("}")
                        if last_brace != -1: json_str = json_str[:last_brace+1]
                    
                    results_data = json.loads(json_str)
                    break # Success
                except json.JSONDecodeError as e:
                    print(f"  âŒ JSON Parse Error: {e}")
                    # If we had a mechanism to feedback to ReAct we would used it.
                    # Since we don't, we break to avoid infinite local loop (logic difference from agent_run)
                    break
                
                current_attempt += 1
            
            final_selection_list = []
            seen_indices = set()
            
            # --- Logic V2: Process JSON 'routes' and 'shortlist' ---
            if results_data and "routes" in results_data and "shortlist" in results_data:
                # 1. Index all analyzed routes by ID
                analyzed_routes_map = {str(r.get("route_id", "0")): r for r in results_data["routes"]}
                
                # 2. Process Shortlist
                top_ids = results_data["shortlist"].get("top_ids", [])
                
                print(f"  ğŸ¤– LLM Shortlisted IDs: {top_ids}")
                
                for tid in top_ids:
                    # Clean ID (e.g., "1" or 1)
                    tid_str = str(tid).strip()
                    route_info = analyzed_routes_map.get(tid_str)
                    
                    if not route_info: 
                        print(f"  âš ï¸ Warning: Shortlisted ID {tid} not found in routes detail.")
                        continue
                        
                    # Map back to original candidate index (1-based -> 0-based)
                    try:
                        # Assuming route_id corresponds to the "Route X" header which was i+1
                        # So ID "1" -> Index 0
                        orig_idx = int(tid_str) - 1
                    except:
                        continue
                        
                    if 0 <= orig_idx < len(candidates) and orig_idx not in seen_indices:
                        cand = candidates[orig_idx]
                        precursors = cand.precursors if hasattr(cand, 'precursors') else cand.get('precursors', [])
                        source = cand.source if hasattr(cand, 'source') else cand.get('source', 'unknown')
                        
                        # Extract rich reasoning from JSON
                        reason_parts = []
                        if route_info.get("rxn_type_from_FG"):
                            reason_parts.append(f"Type: {route_info['rxn_type_from_FG']}")
                        if route_info.get("selectivity_check", {}).get("risk"):
                            risk = route_info["selectivity_check"]["risk"]
                            reason_parts.append(f"Selectivity Risk: {risk}")
                            
                        # Check status
                        status = route_info.get("status", "PASS")
                        if status == "PASS_COND":
                            reason_parts.append(f"[CONDITIONALLY PASSED]: {route_info.get('revision_hint', 'Needs Revision')}")
                        elif status == "FAIL":
                            reason_parts.append(f"[FAILED]: {', '.join(route_info.get('fail_codes', []))}")
                        
                        full_reason = "; ".join(reason_parts)
                        
                        # Fix: Extract actual scores, preserving status
                        extracted_scores = route_info.get("scores", {})
                        if not isinstance(extracted_scores, dict): extracted_scores = {}
                        extracted_scores["status"] = status

                        final_selection_list.append({
                            "rank": len(final_selection_list) + 1,
                            "precursors": list(precursors),
                            "source": source,
                            "reason": full_reason,
                            "scores": extracted_scores, # Contain C/R/S + status
                            "original_index": orig_idx,
                            "analysis_data": route_info # Keep all audit data
                        })
                        seen_indices.add(orig_idx)

                # 3. Process Patched Routes (Auto-Spawn)
                # Look for 'patched_precursors' in ALL routes in JSON (not just shortlisted)
                for r in results_data["routes"]:
                    patch = r.get("patched_precursors")
                    # Check if patch exists and is valid list of strings
                    if patch and isinstance(patch, list) and len(patch) > 0 and isinstance(patch[0], str):
                          # In autonomous mode, we might just log this, BUT agent_full.py can also benefit
                         # from having these in the list.
                         # The autonomous loop uses these candidates in _generate_meta_prompt -> candidates text.
                         
                         # [NEW] Sanity Check for Hallucination
                         from rdkit import Chem
                         valid_patch = True
                         for smi in patch:
                            if not Chem.MolFromSmiles(smi):
                                print(f"  âš ï¸ Warning: LLM suggested invalid SMILES '{smi}'. Discarding patch.")
                                valid_patch = False
                                break
                        
                         if not valid_patch: continue

                         feasibility = r.get("patch_feasibility", "Feasibility check passed")
                         
                         final_selection_list.append({
                            "rank": len(final_selection_list) + 1,
                            "precursors": patch,
                            "source": "LLM_Patch", # Special source ID
                            "reason": f"Auto-Patch from Route {r.get('route_id')}: {feasibility}",
                            "scores": {"status": "PATCHED"},
                            "original_index": -1, # Virtual
                            "reaction_type": r.get("rxn_type_from_FG", "Patched_Rxn")
                         })
            else:
                 print("  âš ï¸ No valid 'routes' or 'shortlist' found in JSON. Falling back to simple parsing or system default.")

            # B. å¡«å……å‰©ä½™ç³»ç»Ÿè·¯çº¿ (ç³»ç»Ÿé»˜è®¤æ’åº)
            for i, cand in enumerate(candidates):
                if i not in seen_indices and len(final_selection_list) < top_n:
                     precursors = cand.precursors if hasattr(cand, 'precursors') else cand.get('precursors', [])
                     source = cand.source if hasattr(cand, 'source') else cand.get('source', 'unknown')
                     conf = getattr(cand, 'confidence', 0.0)
                     final_selection_list.append({
                        "rank": len(final_selection_list) + 1,
                        "precursors": list(precursors),
                        "source": source,
                        "reason": f"System Candidate (Confidence: {conf:.4f}) - Not specifically prioritized by LLM JSON.",
                        "scores": {},
                        "original_index": i
                     })
                     seen_indices.add(i)

            # Note: Removed "LLM Novel" parsing for now as V3.4 prompt focuses on verifying Model/Template candidates.
            # If standardizer/patcher suggests new smiles, they would appear in "patched_route" logic requires Agent 2.
            
            # --- End Logic V2 ---
            # æœ€åå†æˆªæ–­æˆ–è€…ä¿ç•™å‰ 7+N
            # User wants 7 output. Let's return top 7 + Novel (if any)
            # æˆ–è€… strictly 7 system + novel.
            # "å°†æ¯ä¸€æ¬¡ llm æ¨èçš„è·¯çº¿æ•°é‡è¿˜æ˜¯è¾“å‡ºä¸ºä¸ƒæ¡"
            # Let's allow a bit more flexibility but default to showing top 7.
            
            # Logic to Combine and Slice (User Request: System(7) + Novel(All) = 7+N)
            
            # 1. Normalize source casing
            for r in final_selection_list:
                if r['source'].lower() == 'llm_novel':
                    r['source'] = 'llm_novel'
                elif r['source'] == 'LLM_Novel': # safe check
                    r['source'] = 'llm_novel'
            
            # 2. Separate candidates
            system_cands = [x for x in final_selection_list if x['source'] != 'llm_novel']
            novel_cands = [x for x in final_selection_list if x['source'] == 'llm_novel']
            
            # 3. Slice System routes to top_n (e.g., 7)
            # ç¡®ä¿ç³»ç»Ÿè·¯çº¿æœ€å¤šåªæ˜¾ç¤º user è®¾å®šçš„é…é¢ï¼Œé¿å…è¿‡å¤š
            system_selected = system_cands[:top_n]
            
            # 4. Append ALL Novel routes at the end
            # "é¢„ç•™å¸­ä½: æ— è®ºç³»ç»Ÿæ¨èäº†å¤šå°‘æ¡... åˆå¹¶æ˜¾ç¤ºæ€»è·¯çº¿"
            # "é˜Ÿå°¾è¿½åŠ ... ç»ä¸ä¼šè¢«éšæ„ä¸¢å¼ƒ"
            selected = system_selected + novel_cands
            
            # 5. Re-rank (1..N)
            for i, r in enumerate(selected, 1):
                r['rank'] = i
            
            return selected, llm_text
            
        except Exception as e:
            print(f"  [FAIL] LLM Selection Error: {e}")
            return self._heuristic_select(candidates, stock_results, top_n), f"LLM error: {e}"
    
    def _standardize_and_repair_candidates(self, target: str, candidates: List) -> List[Dict]:
        """
        å¯¹å€™é€‰è·¯çº¿è¿›è¡Œæ ‡å‡†åŒ–å’Œæ™ºèƒ½ä¿®å¤
        1. æ£€æŸ¥ RDKit èƒ½å¦è§£æ
        2. å¦‚æœè§£æå¤±è´¥ï¼Œè°ƒç”¨ LLM å°è¯•ç»“åˆç›®æ ‡åˆ†å­ä¸Šä¸‹æ–‡è¿›è¡Œé€»è¾‘ä¿®å¤
        3. ä¿®å¤åå†æ¬¡éªŒè¯ï¼Œè‹¥ä»å¤±è´¥åˆ™èˆå¼ƒ
        4. canonicalize æ‰€æœ‰æˆåŠŸçš„ SMILES
        """
        print(f"  æ­£åœ¨å¤„ç† {len(candidates)} æ¡å€™é€‰è·¯çº¿çš„æ ‡å‡†åŒ–...")
        
        cleaned_candidates = []
        
        for i, cand in enumerate(candidates, 1):
            # è·å–å‰ä½“ (æ³¨æ„å¤„ç†å¯¹è±¡æˆ–æ˜¯å­—å…¸)
            if hasattr(cand, 'precursors'):
                precursors = list(cand.precursors)
                source = getattr(cand, 'source', 'unknown')
            else:
                precursors = list(cand.get("precursors", []))
                source = cand.get("source", "unknown")
            
            valid_precursors = []
            is_broken = False
            
            for smi in precursors:
                # 1. ç›´æ¥å°è¯•è§„èŒƒåŒ–
                canon = self.standardizer.canonicalize(smi)
                if canon:
                    valid_precursors.append(canon)
                else:
                    # 2. å¦‚æœå¤±è´¥ï¼Œå°è¯• LLM ä¿®å¤
                    print(f"    [FAIL] Parse Error in Route {i} ({source}). Invalid SMILES: `{smi}`")
                    repaired = self._repair_broken_smiles(target, smi)
                    
                    if repaired and repaired != "INVALID":
                        # 3. å†æ¬¡éªŒè¯ä¿®å¤åçš„ç»“æœ
                        canon_repaired = self.standardizer.canonicalize(repaired)
                        if canon_repaired:
                            print(f"    [SUCCESS] Repaired -> `{canon_repaired}`")
                            valid_precursors.append(canon_repaired)
                        else:
                            print(f"    [FAIL] Invalid Repair: `{repaired}` still cannot be parsed.")
                            is_broken = True
                            break
                    else:
                        print(f"    [FAIL] LLM could not repair the route.")
                        is_broken = True
                        break
            
            if not is_broken and valid_precursors:
                # è½¬æ¢å›å­—å…¸ä»¥ä¿æŒåç»­å¤„ç†çš„ä¸€è‡´æ€§
                if hasattr(cand, 'to_dict'):
                    cand_dict = cand.to_dict()
                else:
                    cand_dict = cand.copy()
                
                cand_dict["precursors"] = valid_precursors
                cleaned_candidates.append(cand_dict)

        # æ‰“å°æœ€ç»ˆæ ‡å‡†åŒ–çš„è·¯çº¿ (å›å¤ç”¨æˆ·è¦æ±‚ï¼šè¾“å‡ºæ ‡å‡†åŒ–åçš„æ‰€æœ‰è·¯çº¿)
        print(f"\n   [DONE] Standardization & Repair Completed. {len(cleaned_candidates)} valid routes found:")
        for i, c in enumerate(cleaned_candidates, 1):
            src = c.get('source', 'unknown')
            ps = c.get('precursors', [])
            print(f"    [{i:2d}] {src.upper():<10} | {' + '.join(ps)}")
            
        return cleaned_candidates

    def _repair_broken_smiles(self, target: str, broken_smiles: str) -> Optional[str]:
        """åˆ©ç”¨ LLM ç»“åˆä¸Šä¸‹æ–‡å¼ºåˆ¶ä¿®è¡¥ SMILES"""
        if not self.llm_client:
            return None
            
        print(f"    ğŸ§  LLM æ­£åœ¨åˆ†æç›®æ ‡ `{target[:40]}...` å¹¶é‡æ„å‰ä½“ç»“æ„...")
        prompt = get_smiles_repair_prompt(target, broken_smiles)
        
        try:
            response = self.llm_client.chat.completions.create(
                model=CHATGLM_MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯åœ¨æœ‰æœºåˆæˆå’ŒåŒ–å­¦ä¿¡æ¯å­¦é¢†åŸŸæå…¶ä¸¥è°¨çš„ä¸“å®¶ï¼Œåªè¾“å‡º SMILESã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=256,
                temperature=0.1 # æè‡´ç¡®å®šæ€§
            )
            
            repaired_text = response.choices[0].message.content.strip()
            # è¿‡æ»¤å¤šä½™æ–‡å­— (æœ‰äº›æ¨¡å‹å–œæ¬¢å•°å—¦)
            import re
            smi_match = re.search(r'([a-zA-Z0-9@\+\-\[\]\(\)\/\\=#%]{3,})', repaired_text)
            if smi_match:
                return smi_match.group(1)
            return repaired_text
        except Exception as e:
            logger.warning(f"SMILES ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def _parse_llm_system_selection(self, llm_text: str) -> List[Dict]:
        """è§£æ Task 1: è§£æ LLM æ¨èçš„ç³»ç»Ÿè·¯çº¿ç´¢å¼•å’Œç†ç”±"""
        import re
        results = []
        try:
            # æŸ¥æ‰¾ "æ¨èè·¯çº¿:" åŒºå—
            match = re.search(r'æ¨èè·¯çº¿[:ï¼š]([\s\S]*?)(?:### ä»»åŠ¡ 2|### Task 2|$)', llm_text)
            if not match:
                return []
            
            block = match.group(1)
            # åŒ¹é…è¡Œ: "1. è·¯çº¿ X:" æˆ– "1. è·¯çº¿X"
            # æå– X (åŸå§‹ç´¢å¼•)
            items = re.finditer(r'(\d+)\.\s*è·¯çº¿\s*(\d+)', block)
            
            for item in items:
                rank = int(item.group(1))
                route_idx = int(item.group(2)) # è¿™æ˜¯ Prompt ä¸­çš„ "è·¯çº¿ i"
                
                # å°è¯•æå–ç†ç”±å’Œåˆ†æ•° (ç®€å•æå–)
                # å¯»æ‰¾è¯¥é¡¹ä¹‹åçš„å†…å®¹ï¼Œç›´åˆ°ä¸‹ä¸€é¡¹
                start = item.end()
                # æ‰¾ä¸‹ä¸€ä¸ª "d. " æ”¹ä¸ºæ‰¾è¡Œé¦–æ•°å­—
                next_item = re.search(r'\n\d+\.\s*è·¯çº¿', block[start:])
                end = start + next_item.start() if next_item else len(block)
                
                content = block[start:end].strip()
                
                # æå–ç†ç”± (éè´ªå©ªåŒ¹é…ï¼Œç›´åˆ°æ‰“åˆ†è¡Œæˆ–ä¸‹ä¸€é¡¹å¼€å§‹)
                # ä¿®æ”¹æ­£åˆ™ä»¥æ”¯æŒä¸­è‹±æ–‡â€œç†ç”±â€æ ‡ç­¾ï¼Œå¹¶æ›´ç²¾å‡†åœ°æˆªæ–­
                reason_match = re.search(r'ç†ç”±[:ï¼š]\s*([\s\S]+?)(?=\n\s*[C|c][:ï¼š]|\n\d+\.|$)', content)
                reason = reason_match.group(1).strip() if reason_match else ""
                
                # æ¸…æ´—ç†ç”±ä¸­çš„å¹²æ‰°é¡¹
                reason = re.sub(r'\[å¿…é¡»åŒ…å«.*?\]', '', reason) # ç§»é™¤æç¤ºå ä½ç¬¦
                reason = reason.strip()
                
                # æå–åˆ†æ•° (æ–°ç‰ˆ: C/R/S/E/P)
                scores = {}
                # å°è¯•åŒ¹é… C:x R:x S:x E:x P:x
                score_match = re.search(r'[C|c][:ï¼š]\s*(\d+).*?[R|r][:ï¼š]\s*(\d+).*?[S|s][:ï¼š]\s*(\d+)(?:.*?[E|e][:ï¼š]\s*(\d+))?(?:.*?[P|p][:ï¼š]\s*(\d+))?', content)
                if score_match:
                    try:
                        scores['complexity'] = int(score_match.group(1))
                        scores['reactivity'] = int(score_match.group(2))
                        scores['selectivity'] = int(score_match.group(3))
                        if score_match.group(4): scores['efficiency'] = int(score_match.group(4))
                        if score_match.group(5): scores['pg_cost'] = int(score_match.group(5))
                        
                        # V2.2: åŠ æƒç»¼åˆè¯„åˆ†é€»è¾‘
                        weights = SCENARIO_PROFILES.get(CURRENT_SCENARIO, SCENARIO_PROFILES["ACADEMIC"])
                        weighted_sum = sum(
                            scores.get(k, 0) * weights.get(k, 0) 
                            for k in ["complexity", "reactivity", "selectivity", "efficiency", "pg_cost"]
                        )
                        # å¦‚æœæ˜¯ Academic ä¸” E/P ä¸º 0ï¼Œé‡ç®—æƒé‡åˆ†æ¯
                        weight_sum_val = sum(weights.get(k, 0) for k in ["complexity", "reactivity", "selectivity", "efficiency", "pg_cost"] if k in scores or weights.get(k,0) > 0)
                        
                        scores['strategic'] = int(weighted_sum / (weight_sum_val if weight_sum_val > 0 else 1))
                        scores['feasibility'] = scores['strategic']
                    except (ValueError, TypeError):
                        pass
                else:
                    # æ—§ç‰ˆå…¼å®¹
                    strat_match = re.search(r'æˆ˜ç•¥.*(\d+)', content)
                    feas_match = re.search(r'å¯è¡Œæ€§.*(\d+)', content)
                    if strat_match: scores['strategic'] = int(strat_match.group(1))
                    if feas_match: scores['feasibility'] = int(feas_match.group(1))
                
                results.append({
                    "index": route_idx,
                    "reason": reason,
                    "scores": scores
                })
                
        except Exception as e:
            print(f"  âš ï¸ è§£æé€‰è·¯å¤±è´¥: {e}")
            
        return results

    def _parse_llm_novel_routes(self, llm_text: str) -> List[Dict]:
        """ä» LLM å“åº”ä¸­è§£ææ–°é¢–è·¯çº¿ææ¡ˆ"""
        import re
        
        novel_routes = []
        
        try:
            # å°è¯•åŒ¹é… "LLM æ–°é¢–è·¯çº¿" æˆ–ç±»ä¼¼æ¨¡å¼
            # æŸ¥æ‰¾ "ååº”ç±»å‹:" å’Œ "å‰ä½“ SMILES:" æ¨¡å¼
            
            # æ¨¡å¼1: ç»“æ„åŒ–æ ¼å¼ (å¢å¼ºç‰ˆ: å…¼å®¹ Markdown bold, list identifiers)
            # å…è®¸å‰ç¼€å¦‚ "1. " æˆ– "* " æˆ– "**"
            reaction_pattern = r'(?:[\*\-]?\s*\d+\.?\s*)?[\*]*ååº”ç±»å‹[\*]*[ï¼š:]\s*(.+?)(?:\n|$)'
            # å…è®¸ "å‰ä½“ SMILES" æˆ– "å‰ä½“" (æ³¨æ„ \s* å¤„ç†ç©ºæ ¼)
            precursor_pattern_token = r'[\*]*å‰ä½“\s*(?:SMILES)?[\*]*[ï¼š:]'
            reason_pattern = r'[\*]*ç†ç”±[\*]*[ï¼š:]\s*(.+?)(?:\n\n|\n(?=\d\.)|\n[CSR][:ï¼š]|$)'
            
            # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…
            text_lower = llm_text
            
            # åˆ†æ®µæŸ¥æ‰¾ (ä¿ç•™ split é€»è¾‘ä¸å˜ï¼Œä¸»è¦å¢å¼ºå†…éƒ¨æå–)
            sections = re.split(r'\n(?=\d+\.)', text_lower)
            
            for section in sections:
                if 'ååº”ç±»å‹' in section or 'LLM' in section.upper():
                    route = {}
                    
                    # æå–ååº”ç±»å‹
                    reaction_match = re.search(reaction_pattern, section)
                    if reaction_match:
                        # ç§»é™¤å¯èƒ½çš„ Markdown bold markers
                        rtype = reaction_match.group(1).strip()
                        route['reaction_type'] = rtype.replace('**', '').replace('__', '')
                    
                # æå–å‰ä½“ (Generalized for 1 or more components)
                # Pattern: "å‰ä½“ ... : [smiles] + [smiles]"
                # ç­–ç•¥: æ•è·å†’å·åçš„æ•´è¡Œï¼Œç„¶ååˆ†å‰²
                precursor_line_match = re.search(fr'{precursor_pattern_token}\s*([^\n]+)', section, re.IGNORECASE)
                if precursor_line_match:
                    raw_line = precursor_line_match.group(1).strip()
                    # ç§»é™¤å¯èƒ½çš„åå¼•å·å’Œ bold
                    clean_line = raw_line.replace('`', '').replace('**', '')
                    # åˆ†å‰² (æ”¯æŒ + æˆ– ,)
                    parts = re.split(r'\s*[+,]\s*', clean_line)
                    parts = [p.strip() for p in parts if p.strip()]
                    
                    if parts:
                        route['precursors'] = " + ".join(parts)
                        route['precursors_list'] = parts
                    
                    # æå–ç†ç”± (å¢åŠ é•¿åº¦é™åˆ¶åˆ° 200)
                    reason_match = re.search(reason_pattern, section, re.DOTALL)
                    if reason_match:
                        route['reason'] = reason_match.group(1).strip()[:200]
                    
                    # æå–æ‰“åˆ† (C:x R:y S:z E:a P:b)
                    scores_match = re.search(r'C[:ï¼š]\s*(\d+)\s*R[:ï¼š]\s*(\d+)\s*S[:ï¼š]\s*(\d+)(?:\s*E[:ï¼š]\s*(\d+))?(?:\s*P[:ï¼š]\s*(\d+))?', section)
                    if scores_match:
                        route['scores'] = {
                            'complexity': int(scores_match.group(1)),
                            'reactivity': int(scores_match.group(2)),
                            'selectivity': int(scores_match.group(3))
                        }
                        if scores_match.group(4): route['scores']['efficiency'] = int(scores_match.group(4))
                        if scores_match.group(5): route['scores']['pg_cost'] = int(scores_match.group(5))
                    else:
                        route['scores'] = {}
                    
                    if route.get('precursors_list'):
                        novel_routes.append(route)
            
        except Exception as e:
            logger.debug(f"è§£æ LLM æ–°é¢–è·¯çº¿å¤±è´¥: {e}")
        
        return novel_routes
    
    def _heuristic_select(self, candidates: List, stock_results: Dict, top_n: int) -> List[Dict]:
        """å¯å‘å¼é€‰æ‹©"""
        stock_map = {r["smiles"]: r["in_stock"] for r in stock_results["results"]}
        
        scored = []
        for cand in candidates:
            score = 0
            precursors = cand.precursors if hasattr(cand, 'precursors') else cand.get('precursors', [])
            source = cand.source if hasattr(cand, 'source') else cand.get('source', 'unknown')
            confidence = cand.confidence if hasattr(cand, 'confidence') else cand.get('confidence', 0)
            
            # æ¥æºåŠ åˆ†
            if source == "template":
                score += 10
            elif source == "both":
                score += 15
            
            # å¯è´­ä¹°åŠ åˆ†
            stock_count = sum(1 for p in precursors if stock_map.get(p, False))
            score += stock_count * 20
            
            # ç½®ä¿¡åº¦
            score += confidence * 10
            
            scored.append((score, cand))
        
        scored.sort(reverse=True, key=lambda x: x[0])
        
        results = []
        for rank, (score, cand) in enumerate(scored[:top_n], 1):
            precursors = cand.precursors if hasattr(cand, 'precursors') else cand.get('precursors', [])
            source = cand.source if hasattr(cand, 'source') else cand.get('source', 'unknown')
            
            results.append({
                "rank": rank,
                "precursors": list(precursors),
                "source": source,
                "reason": f"å¯å‘å¼è¯„åˆ†: {score:.1f}",
            })
        
        return results
    
    def run_full_planning(self, target_smiles: str, max_stages: int = None) -> Dict:
        """
        è¿è¡Œå®Œæ•´çš„å¤šé˜¶æ®µè§„åˆ’
        
        å¾ªç¯è¿­ä»£å·¥ä½œæ¨¡å—ç›´åˆ°ï¼š
        - æ‰€æœ‰åˆ†å­å¯è´­ä¹° (æˆåŠŸ)
        - ç”¨æˆ·ç»ˆæ­¢
        - (å¯é€‰) è¾¾åˆ°æœ€å¤§é˜¶æ®µæ•°
        
        Args:
            target_smiles: ç›®æ ‡åˆ†å­
            max_stages: æœ€å¤§é˜¶æ®µæ•°ï¼Œé»˜è®¤ä¸º None (æ— é™åˆ¶ï¼Œç”±åˆæˆäººå‘˜åˆ¤æ–­)
        """
        print("\n" + "*" * 70)
        print("****** å¯åŠ¨å…¨æµç¨‹é€†åˆæˆè§„åˆ’ (MoleReact V2.2) ******")
        print("*" * 70)
        print(f"  ç›®æ ‡åˆ†å­: {target_smiles[:60]}...")
        print(f"  é˜¶æ®µé™åˆ¶: {max_stages if max_stages else 'æ— é™åˆ¶ (äººå·¥æ§åˆ¶)'}")
        print(f"  è¿è¡Œæ¨¡å¼: {'è‡ªåŠ¨' if self.auto_mode else 'äººæœºäº¤äº’'}")
        
        current_target = target_smiles
        stage = 1
        history_context = ""
        
        # å°è¯•æ¢å¤ä¼šè¯
        # å°è¯•æ¢å¤ä¼šè¯
        if not self.auto_mode:
            latest_session = self.session_logger.get_latest_context()
            if latest_session["exists"]:
                print(f"\n[è­¦å‘Š] å‘ç°ä¹‹å‰çš„ä¼šè¯è®°å½• ({latest_session['session_id']})")
                resume_input = input("æ˜¯å¦æ¢å¤ä¼šè¯? (è¾“å…¥è·¯å¾„æˆ– [y/n]) [y]: ").strip()
                
                # ... 
                load_path = latest_session.get("path")
                if resume_input.lower() in ["", "y", "yes"]:
                    pass # ä½¿ç”¨å‘ç°çš„æœ€æ–°çš„è·¯å¾„
                elif resume_input.lower() not in ["n", "no"]:
                    if os.path.exists(resume_input):
                        load_path = resume_input
                    else:
                        print(f"[å¤±è´¥] æœªæ‰¾åˆ°æ–‡ä»¶: {resume_input}. è·³è¿‡æ¢å¤ã€‚")
                
                if resume_input.lower() not in ["n", "no"]:
                    print("  [ç­‰å¾…] æ­£åœ¨é‡å»ºä¼šè¯ä¸Šä¸‹æ–‡ä¸­...")
                    
                    # 1. æ¢å¤ Cumulative Route (æ ¸å¿ƒçŠ¶æ€)
                    restored_route = self.session_logger.restore_session_state(load_path)
                    
                    if restored_route and restored_route.get("stages"):
                        print(f"  [æˆåŠŸ] å·²æ¢å¤ {len(restored_route['stages'])} ä¸ªå†å²é˜¶æ®µæ•°æ®ã€‚")
                        cumulative_route = restored_route
                        
                        # ...
                        
                        if global_unsolved_queue:
                            current_target = global_unsolved_queue[0][0] if isinstance(global_unsolved_queue[0], tuple) else global_unsolved_queue[0]
                            print(f"  â¡ï¸ æ¢å¤ç›®æ ‡: {current_target} (å¾…è§£é˜Ÿåˆ—: {len(global_unsolved_queue)})")
                        else:
                            print(f"  âš ï¸ ä¸Šä¸€é˜¶æ®µæ— æœªè§£å†³åˆ†å­ï¼Œå¯èƒ½å·²å®Œæˆï¼Ÿé‡ç½®ç›®æ ‡ä¸ºåŸå§‹ç›®æ ‡ã€‚")
                            current_target = target_smiles
                            
                        # 2. æ¢å¤ LLM Context String
                        history_context = self.session_logger.load_history_context(load_path)
                        print(f"  ğŸ“œ å·²æ¢å¤å†å²æ–‡æœ¬ä¸Šä¸‹æ–‡ ({len(history_context)} å­—ç¬¦)")
                    else:
                        print("  âš ï¸ çŠ¶æ€é‡å»ºä¸ºç©ºï¼Œå°†ä»…åŠ è½½æ–‡æœ¬ä¸Šä¸‹æ–‡ã€‚")
                        history_context = self.session_logger.load_history_context(load_path)
        
        print(f"  ğŸ“ Session Log loaded? {'Yes' if history_context else 'No'}")
        
        # ç´¯ç§¯è·¯çº¿æ•°æ® (ç”¨äºæœ€ç»ˆæŠ¥å‘Š)
        # å¦‚æœæœªä» session æ¢å¤ï¼Œåˆ™åˆå§‹åŒ–
        if 'cumulative_route' not in locals() or cumulative_route is None:
            cumulative_route = {
                "target": target_smiles,
                "stages": [],
                "status": "running",
                "global_unsolved_queue": [(target_smiles, [], "1")] # å­˜å‚¨ (SMILES, Lineage, PathID)
            }
            # ç¡®ä¿ current_target åˆå§‹æ­£ç¡®
            current_target = target_smiles
            
        # ç¡®ä¿ global_unsolved_queue å­˜åœ¨ (å…¼å®¹æ—§æ—¥å¿—æ¢å¤)
        if "global_unsolved_queue" not in cumulative_route:
            cumulative_route["global_unsolved_queue"] = [(current_target, [], "1")] if current_target else []

        # é’ˆå¯¹å†å²æ•°æ®æ¢å¤çš„å…¼å®¹å¤„ç† (å¦‚æœå­˜çš„æ˜¯ SMILES æˆ– (SMILES, []) åˆ™è½¬ä¸º (SMILES, [], PathID))
        fixed_queue = []
        for i, item in enumerate(cumulative_route["global_unsolved_queue"]):
            if isinstance(item, str):
                fixed_queue.append((item, [], f"{i+1}"))
            elif len(item) == 2:
                fixed_queue.append((item[0], item[1], f"1.{i+1}"))
            else:
                fixed_queue.append(item)
        cumulative_route["global_unsolved_queue"] = fixed_queue

        # åŒæ­¥æœ¬åœ°å˜é‡å¼•ç”¨
        global_unsolved_queue = cumulative_route["global_unsolved_queue"]
        
        try:
            while True:
                # æ£€æŸ¥æœ€å¤§é˜¶æ®µé™åˆ¶ (å¦‚æœè®¾ç½®)
                if max_stages and stage > max_stages:
                    print(f"\nâš ï¸ å·²è¾¾åˆ°æœ€å¤§é˜¶æ®µæ•° ({max_stages})")
                    break
                
                # è¿è¡Œå·¥ä½œæ¨¡å— (ä¼ å…¥å†å²ä¸Šä¸‹æ–‡ å’Œ cumulative_route)
                
                # ä»é˜Ÿåˆ—ä¸­å–å‡ºå½“å‰ç›®æ ‡
                if not global_unsolved_queue:
                    print("\nâœ… æ‰€æœ‰åˆ†å­å‡å·²è§£å†³æˆ–å¯è´­ä¹°ï¼")
                    break
                
                current_node = global_unsolved_queue.pop(0)
                current_target, current_lineage, current_path_id = current_node
                
                # Path-Aware Loop Detection
                if current_target in current_lineage:
                    print(f"\n[ä¸¥é‡è­¦å‘Š: å‘ç°è·¯çº¿æ­»å¾ªç¯] åˆ†å­ `{current_target}` åœ¨å…¶æ‰€å±è°±ç³»è·¯å¾„ä¸­é‡å¤å‡ºç°ï¼")
                    print(f"  è·¯å¾„: {' -> '.join(current_lineage + [current_target])}")
                    if not self.auto_mode:
                        c_choice = input("æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†æ­¤èŠ‚ç‚¹? (y/n) [n]: ").strip().lower()
                        if c_choice != 'y':
                            continue
                
                # æ›´æ–° Lineage
                new_lineage = current_lineage + [current_target]
                
                # æ„å»ºç»“æ„åŒ–çš„å…¨æ™¯èƒŒæ™¯ Context (V2.2 å¼ºåŒ–)
                # 1. å…¨å±€è¿›åº¦ (å·²è§£å‡ºçš„åˆ†å­å¯¹)
                global_progress = "### 1. å…¨å±€åˆæˆè¿›åº¦ (Global Progress):\n"
                if cumulative_route["stages"]:
                    for s in cumulative_route["stages"]:
                        t_smi = s.get("target", "Unknown")
                        p_smis = s.get("precursors", [])
                        pid = s.get("path_id", "Unknown")
                        global_progress += f"- [Node {pid}] {t_smi} => {' + '.join(p_smis)}\n"
                else:
                    global_progress += "- (åˆå§‹ç›®æ ‡ï¼Œæ­£åœ¨å¼€å¯ç¬¬ä¸€æ­¥)\n"
                
                # 2. å½“å‰è·¯å¾„è¿½è¸ª (Path-Aware Lineage)
                path_lineage = f"\n### 2. å½“å‰åˆ†å­è°±ç³»è·¯å¾„ (Current Path: {current_path_id}):\n"
                if current_lineage:
                    path_lineage += " -> ".join(current_lineage) + f" -> **{current_target}**"
                else:
                    path_lineage += f"**{current_target}** (æ ¹èŠ‚ç‚¹ç›®æ ‡)"
                
                full_context = global_progress + path_lineage
                
                result = self.run_work_module(current_target, stage=stage, topk=10, history_context=full_context, path_id=current_path_id)
                
                # Check if complete
                if result.is_complete:
                    print("\n" + "*" * 70)
                    print("****** è§„åˆ’ä»»åŠ¡åœ†æ»¡å®Œæˆ ******")
                    print("*" * 70)
                    cumulative_route["status"] = "completed"
                    return self._generate_final_report("complete")
                
                # Interactive Mode
                if not self.auto_mode:
                    print("\n" + "*" * 60)
                    print(f"****** äººæœºäº¤äº’å†³ç­– (èŠ‚ç‚¹: {current_path_id}) ******")
                # ==========================================================================================
                # ğŸ”„ äº¤äº’å— (Interaction Block)
                # ==========================================================================================
                interaction_active = True
                selected_route_idx = -1
                
                while interaction_active:
                    if self.auto_mode:
                        # è‡ªåŠ¨æ¨¡å¼ä¸‹è·³è¿‡äº¤äº’ï¼Œé»˜è®¤é€‰æ‹©ç¬¬ 0 æ¡ (Top-1)
                        selected_route_idx = 0
                        interaction_active = False # Exit loop
                    else:
                        print("*" * 60)
                        # æ˜¾ç¤ºå¾…æ‹†è§£åˆ†å­é˜Ÿåˆ—
                        if global_unsolved_queue:
                            print(f"  ğŸ“‹ å¾…åˆæˆåˆ†å­é˜Ÿåˆ— (å¾…è§£åˆ†æ”¯):")
                            for idx, (mol, lineage, pid) in enumerate(global_unsolved_queue, 1):
                                depth = len(lineage)
                                print(f"    [Q{idx}] {mol[:40]}... (ID: {pid}, æ·±åº¦: {depth})")
                        
                        print("-" * 60)
                        print("  æ“ä½œæŒ‡ä»¤:")
                        print("    [å›è½¦]         - å¯¹å½“å‰ç›®æ ‡ä½¿ç”¨è·¯çº¿ 1")
                        print("    æ•°å­—           - é€‰æ‹©å½“å‰ç›®æ ‡çš„ç‰¹å®šè·¯çº¿ (å¦‚: 2)")
                        print("    switch [Qn]    - åˆ‡æ¢åˆ°å¦ä¸€ä¸ªå¾…è§£åˆ†å­ (å¦‚: switch Q1)")
                        print("    list           - æŸ¥çœ‹å½“å‰å®Œæ•´çš„åˆæˆæ ‘æ–¹æ¡ˆä¸è¿›åº¦")
                        print("    reopen [ID]    - é‡æ–°æ‰“å¼€å¹¶è°ƒæ•´æŸä¸ªå·²å¤„ç†çš„èŠ‚ç‚¹ (å¦‚: reopen 1.1)")
                        print("    q/stop/é€€å‡º    - ç»ˆæ­¢è§„åˆ’")
                        print("    verify/éªŒè¯    - æ ‡è®°å½“å‰é˜¶æ®µå¾…å®éªŒéªŒè¯")
                        print("-" * 60)
                    
                        user_input = input(">>> (è¯·é€‰æ‹©æˆ–è¾“å…¥æŒ‡ä»¤): ").strip()
                        
                        # Command 1: ç»ˆæ­¢
                        if user_input.lower() in ["ç»ˆæ­¢", "stop", "quit", "q", "é€€å‡º"]:
                            print("\n ç”¨æˆ·ç»ˆæ­¢è§„åˆ’")
                            return self._generate_final_report("terminated_by_user")
                        
                        # Command 2: æ–¹æ¡ˆæŸ¥çœ‹ (List) - ä¿æŒåœ¨äº¤äº’å—
                        if user_input.lower() in ["list", "æ–¹æ¡ˆ", "æŸ¥çœ‹"]:
                            print("\n" + "=" * 60)
                            print("ğŸ“œ å½“å‰åˆæˆæ–¹æ¡ˆæ±‡æ€» (Current Tree Summary):")
                            for s_idx, s in enumerate(cumulative_route["stages"], 1):
                                print(f"  [{s['path_id']}] {s['target'][:40]} => {' + '.join(s['precursors'])}")
                            if global_unsolved_queue:
                                print(f"  â³ å¾…åˆæˆåˆ†å­: {len(global_unsolved_queue)} ä¸ª")
                            print("=" * 60)
                            continue # Stay in interaction loop
                        
                        # Command 3: éªŒè¯æ ‡è®° (Verify) - ä¿æŒåœ¨äº¤äº’å—ï¼Œæ”¯æŒè¿›ä¸€æ­¥äº¤äº’
                        if any(x in user_input for x in ["å¾…éªŒè¯", "éªŒè¯", "verify"]):
                            print("  [æç¤º] å·²å°†å½“å‰é˜¶æ®µæ ‡è®°ä¸ºå¾…å®éªŒéªŒè¯ã€‚")
                            self.session_logger.log_event(
                                title="å®éªŒéªŒè¯æ ‡è®° (Verification Required)",
                                content=f"ç”¨æˆ·å°†å¯¹èŠ‚ç‚¹ `{current_path_id}` (ç›®æ ‡: `{current_target}`) çš„å†³ç­–æ ‡è®°ä¸ºéœ€è¦è¿›ä¸€æ­¥å®éªŒå®¤éªŒè¯ã€‚",
                                level="WARNING"
                            )
                            
                            # V2.2: True Tool Use (ReAct Hook)
                            # User requested explicit verification, allowing LLM to dynamically call tools.
                            if self.use_llm and self.llm_client:
                                try:
                                    print("\n  ğŸ” [ReAct] Initializing Dynamic Analysis Session...")
                                    from multistep.agent.tools.base import ToolRegistry
                                    # Create specific registry for this session
                                    temp_registry = ToolRegistry()
                                    # Register available tools (Anal analysis is most relevant here)
                                    temp_registry.register(self.analyzer) # MoleculeAnalysisTool
                                    
                                    # Instantiate ReAct Session
                                    react = ReActSession(self.llm_client, temp_registry)
                                    
                                    # Define Goal
                                    goal = f"Verify the chemical stability and potential risks for molecule: {current_target}. Use the MoleculeAnalysisTool to get properties."
                                    
                                    # Run
                                    print("  ğŸ¤– Agent is thinking and acting...")
                                    react_result = react.run(goal)
                                    
                                    print(f"  ğŸ“ [ReAct Conclusion]: {react_result}")
                                    
                                    # Inject into context for next turn
                                    # We append this to a temporary note or history
                                    self.session_logger.log_event("ReAct Analysis", react_result, "INFO")
                                    print("  [Info] ReAct analysis result logged.")
                                    
                                except Exception as e:
                                    print(f"  [Error] ReAct execution failed: {e}")
                            else:
                                print("  [Info] LLM not available for dynamic analysis.")

                            print("  [æç¤º] æ‚¨å¯ä»¥ç»§ç»­è¾“å…¥æŒ‡ä»¤ (å¦‚é€‰æ‹©è·¯çº¿æˆ–åˆ‡æ¢åˆ†æ”¯)ã€‚")
                            continue

                        # Command 4: åˆ†æ”¯åˆ‡æ¢ (Switch) - é€€å‡ºäº¤äº’å—ï¼Œé‡æ–°å¼€å§‹å¤§å¾ªç¯
                        if user_input.lower().startswith("switch"):
                            target_match = re.search(r'[Qq](\d+)', user_input)
                            if target_match:
                                q_idx = int(target_match.group(1)) - 1
                                if 0 <= q_idx < len(global_unsolved_queue):
                                    # Logic to switch queue
                                    global_unsolved_queue.insert(0, current_node)
                                    selected_node = global_unsolved_queue.pop(q_idx + 1)
                                    global_unsolved_queue.insert(0, selected_node)
                                    
                                    self.session_logger.log_event(
                                        title="åˆ†æ”¯åˆ‡æ¢ (Branch Switch)",
                                        content=f"ç”¨æˆ·é€šè¿‡ `switch Q{q_idx+1}` åˆ‡æ¢äº†åˆ†æ”¯ã€‚\n- åŸç›®æ ‡: `{current_node[0]}`\n- æ–°ç›®æ ‡: `{selected_node[0]}` (ID: {selected_node[2]})",
                                        level="INFO"
                                    )
                                    print(f"  ğŸ”„ åˆ†æ”¯å·²åˆ‡æ¢ï¼ä¸‹ä¸€ä¸ªç›®æ ‡å°†æ˜¯: {selected_node[0][:40]}")
                                    selected_route_idx = -999 # Signal to skip current route processing
                                    interaction_active = False # Break interaction loop
                                    break 
                                else:
                                    print(f"  [è­¦å‘Š] æ— æ•ˆçš„ä»»åŠ¡ç¼–å·: Q{q_idx+1}")
                                    continue
                            else:
                                print(f"  [ç”¨æ³•å‚è€ƒ] switch Q1 / switch 1")
                                continue

                        # Command 5: èŠ‚ç‚¹é‡å¯ (Reopen) - é€€å‡ºäº¤äº’å—ï¼Œé‡æ–°å¼€å§‹å¤§å¾ªç¯
                        if user_input.lower().startswith("reopen"):
                            pid_match = re.search(r'([\d\.]+)', user_input[6:])
                            if pid_match:
                                target_pid = pid_match.group(1)
                                found_idx = -1
                                target_mol = None
                                target_lineage = []
                                for i, s in enumerate(cumulative_route["stages"]):
                                    if s["path_id"] == target_pid:
                                        found_idx = i
                                        target_mol = s["target"]
                                        target_lineage = s.get("lineage", [])
                                        break
                                
                                if found_idx != -1:
                                    remaining_stages = []
                                    for i, s in enumerate(cumulative_route["stages"]):
                                        if s["path_id"] == target_pid or s["path_id"].startswith(target_pid + "."):
                                            continue
                                        remaining_stages.append(s)
                                    cumulative_route["stages"] = remaining_stages
                                    
                                    self.session_logger.log_reopen(path_id=target_pid, target_smiles=target_mol, reason="ç”¨æˆ·ä¸»åŠ¨è¯·æ±‚é‡æ–°è¯„ä¼°")
                                    global_unsolved_queue.insert(0, (target_mol, target_lineage, target_pid))
                                    print(f"  â™»ï¸ èŠ‚ç‚¹ {target_pid} å·²é‡æ–°å¼€å¯ã€‚")
                                    selected_route_idx = -999 # Signal skip
                                    interaction_active = False
                                    break
                                else:
                                    print(f"  [ERROR] Path ID {target_pid} not found.")
                                    continue
                            else:
                                print(f"  [USAGE] reopen 1.1")
                                continue

                        # Command 6: è·¯çº¿é€‰æ‹© (Default) - é€€å‡ºäº¤äº’å—ï¼Œç»§ç»­æµç¨‹
                        import re
                        digit_match = re.search(r'(\d+)', user_input)
                        if digit_match:
                             route_num = int(digit_match.group(1))
                             if 1 <= route_num <= len(result.llm_selected_top_n):
                                 selected_route_idx = route_num - 1
                                 print(f"  [ç¡®å®š] å·²åˆ‡æ¢è‡³è·¯çº¿ {route_num}")
                                 interaction_active = False # Break interaction loop
                                 # Fall through to process selection
                             else:
                                 print(f"  [è­¦å‘Š] æ— æ•ˆçš„è·¯çº¿ç¼–å· {route_num}")
                                 continue
                        elif user_input == "" or user_input.lower() in ["ç»§ç»­", "continue"]:
                            selected_route_idx = 0 # Default to 1
                            print(f"  [ç¡®å®š] é»˜è®¤ä½¿ç”¨è·¯çº¿ 1")
                            interaction_active = False
                        else:
                             # treat as note or invalid
                             print(f"  [æç¤º] æ— æ³•è¯†åˆ«æŒ‡ä»¤ '{user_input}'. è¾“å…¥æ•°å­—é€‰æ‹©è·¯çº¿ï¼Œæˆ– 'list' æŸ¥çœ‹è¯¦æƒ…ã€‚")
                             continue

                # ==========================================================================================
                # ğŸ”„ å¤„ç†äº¤äº’ç»“æœ (Process Result)
                # ==========================================================================================
                
                # Check for Skip signals (Switch/Reopen triggered)
                if selected_route_idx == -999:
                     continue # Skip to next outer loop iteration (Queue has been modified)

                # Process Route Selection
                if 0 <= selected_route_idx < len(result.llm_selected_top_n):
                    chosen_route = result.llm_selected_top_n[selected_route_idx]
                    route_desc = f"Stage {stage} é€‰æ‹©äº†è·¯çº¿ {selected_route_idx+1} ({chosen_route.get('source')})"
                    
                    # Update History Context
                    history_context = f"- ä¸Šä¸€é˜¶æ®µ ({stage}) å†³ç­–: {route_desc}\n"
                    # Add user note if any (Simplified refactor: previously checked user_input again)
                    # self.session_logger.log_decision(...) 
                    
                    # Reconstruction stock_map
                    current_stock_map = {r["smiles"]: r["in_stock"] for r in result.stock_results.get("results", [])}
                    if "stock_check" in chosen_route:
                        for smi, info in chosen_route["stock_check"].items():
                            current_stock_map[smi] = info.get("in_stock", False)

                    # LLM Correction Logic (Keep existing)
                    precursors = chosen_route.get("precursors", [])
                    reason_text = chosen_route.get("reason", "")
                    correction_match = re.search(r'å·²ä¿®æ­£\s*SMILES[:ï¼š]\s*(\[?[^\]\n]+\]?)', reason_text)
                    if correction_match:
                        correction_str = correction_match.group(1).strip()
                        clean_corr = correction_str.replace('`', '').replace('[', '').replace(']', '')
                        corr_parts = [p.strip() for p in re.split(r'\s*[+,]\s*', clean_corr) if p.strip()]
                        valid_corr_parts = []
                        for p in corr_parts:
                            canon_p = self.standardizer.canonicalize(p)
                            if canon_p: valid_corr_parts.append(canon_p)
                        if len(valid_corr_parts) == len(corr_parts):
                            precursors = valid_corr_parts
                            chosen_route["precursors"] = precursors

                    result.unsolved_leaves = [p for p in precursors if not current_stock_map.get(p, False)]
                    
                    # Log Decision
                    self.session_logger.log_decision(stage, selected_route_idx, chosen_route, "", global_unsolved_queue=global_unsolved_queue)

                    # Update Cumulative Route
                    cumulative_route["stages"].append({
                        "stage": stage,
                        "path_id": current_path_id,
                        "target": current_target,
                        "lineage": current_lineage,
                        "action": f"é€‰æ‹©äº†è·¯çº¿ {selected_route_idx + 1}",
                        "precursors": precursors,
                        "unsolved_leaves": result.unsolved_leaves,
                        "reaction_type": chosen_route.get("reaction_type", ""),
                        "reason": chosen_route.get("reason", "")
                    })
            
                # Update Global Queue (Depth-First)
                if result.unsolved_leaves:
                    new_nodes = []
                    for child_idx, m in enumerate(result.unsolved_leaves, 1):
                        if m not in new_lineage:
                            child_pid = f"{current_path_id}.{child_idx}"
                            new_nodes.append((m, new_lineage, child_pid))
                    
                    cumulative_route["global_unsolved_queue"] = new_nodes + global_unsolved_queue
                    global_unsolved_queue = cumulative_route["global_unsolved_queue"]
                    print(f"\n[ä¸‹ä¸€æ­¥] æ–°å¢åˆ†æ”¯: {len(new_nodes)}, é˜Ÿåˆ—æ€»è®¡: {len(global_unsolved_queue)}")
                else:
                    if global_unsolved_queue:
                        next_node = global_unsolved_queue[0]
                        self.session_logger.log_event("åˆ†æå·²è§£å†³", f"èŠ‚ç‚¹ {current_path_id} å®Œæˆã€‚åˆ‡æ¢è‡³: {next_node[0]}", "SUCCESS")
                        print(f"\nâœ¨ [åˆ†æè§£å†³] èŠ‚ç‚¹ {current_path_id} å·²æˆåŠŸæ‹†è§£ã€‚")
                    else:
                        print("\n[é¡ºåˆ©å®Œæˆ] é€†åˆæˆæ ‘è§£æå®Œæ¯•ã€‚")
                        break
                
                stage += 1
        
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ (KeyboardInterrupt)")
            cumulative_route["status"] = "interrupted"
        except Exception as e:
            print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            cumulative_route["status"] = "error"
        finally:
            # æ— è®ºå¦‚ä½•é€€å‡º (å®Œæˆã€ç»ˆæ­¢ã€æŠ¥é”™)ï¼Œéƒ½ç”Ÿæˆæœ€ç»ˆå¯è§†åŒ–å’ŒæŠ¥å‘Š
            print("\nğŸ”„ æ­£åœ¨ç”Ÿæˆæœ€ç»ˆä¼šè¯æŠ¥å‘Šä¸è·¯å¾„å›¾...")
            self._finalize_session(cumulative_route)
        
        return self._generate_final_report("completed")

    def _convert_to_aizynth_dict(self, cumulative_route: Dict) -> Dict:
        """Convert cumulative route stages to AiZynthFinder tree dict"""
        target_to_stage = {}
        
        # Build lookup map: Target -> Stage Data
        for s in cumulative_route["stages"]:
            t = s["target"]
            target_to_stage[t] = s
        
        def build_node(mol_smiles: str, depth: int = 0, built_visited: set = None) -> Dict:
            if built_visited is None:
                built_visited = set()
                
            # é˜²å¾¡æ€§ç¼–ç¨‹ï¼šé˜²æ­¢å¾ªç¯å¼•ç”¨å¯¼è‡´çš„æ— é™é€’å½’
            if mol_smiles in built_visited or depth > 20:
                return {
                    "type": "mol",
                    "smiles": mol_smiles,
                    "is_chemical": True,
                    "in_stock": False,
                    "metadata": {"warning": "Recursive path detected or depth limit exceeded"}
                }
            
            built_visited.add(mol_smiles)
            
            node = {
                "type": "mol",
                "smiles": mol_smiles,
                "is_chemical": True, 
                "in_stock": self.stock_cache.get(mol_smiles, False) # ä½¿ç”¨ç¼“å­˜çš„åº“å­˜çŠ¶æ€
            }
            
            # If this mol was a target in some stage, it means we expanded it
            if mol_smiles in target_to_stage:
                stage_data = target_to_stage[mol_smiles]
                precursors = stage_data.get("precursors", [])
                
                # Construct reaction child
                rxn_smiles = ".".join(precursors) + ">>" + mol_smiles
                
                reaction_node = {
                    "type": "reaction",
                    "smiles": rxn_smiles,
                    "metadata": {
                        "path_id": stage_data.get("path_id", "Unknown"),
                        "reaction_type": stage_data.get("reaction_type", "Unknown"),
                        "reason": stage_data.get("action", "")
                    },
                    "children": []
                }
                
                for p in precursors:
                    reaction_node["children"].append(build_node(p, depth + 1, built_visited.copy()))
                
                node["children"] = [reaction_node]
            
            return node

        if not cumulative_route.get("target"):
            return {}
            
        return build_node(cumulative_route["target"])

    def _finalize_session(self, cumulative_route: Dict):
        """Finalizing session: Generate summary visualization and log."""
        print("\n" + "*" * 70)
        print("****** æ­£åœ¨ç»“é¡¹å¹¶ç”Ÿæˆæ±‡æ€»æ•°æ® ******")
        print("*" * 70)
        try:
            image_path = None
            
            # 1. å°è¯•ä½¿ç”¨ AiZynthFinder é£æ ¼é«˜çº§å¯è§†åŒ– (Reference 1.py)
            try:
                from aizynthfinder.reactiontree import ReactionTree
                tree_dict = self._convert_to_aizynth_dict(cumulative_route)
                
                if tree_dict:
                    img_name = f"tree_full_{datetime.now().strftime('%H%M%S')}.png"
                    img_path_aizynth = os.path.join(self.output_dir, img_name)
                    
                    # ç”Ÿæˆå›¾ç‰‡
                    ReactionTree.from_dict(tree_dict).to_image().save(img_path_aizynth)
                    print(f"  ğŸ–¼ï¸ [AiZynth] å…¨æ™¯é€†åˆæˆè·¯çº¿å›¾å·²ç”Ÿæˆ: {img_path_aizynth}")
                    image_path = img_path_aizynth
            except ImportError:
                print("  âš ï¸ æœªæ‰¾åˆ° aizynthfinder åº“ï¼Œå°è¯•ä½¿ç”¨æ™®é€šå¯è§†åŒ–ã€‚")
            except Exception as e:
                print(f"  âš ï¸ AiZynth å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            
            # 2. å¦‚æœé«˜çº§å¯è§†åŒ–å¤±è´¥æˆ–æœªå¯ç”¨ï¼Œä½¿ç”¨ stage_visualize (Fallback)
            if not image_path:
                from multistep.agent.tools import VisualizationTool
                # æå–æœ€åä¸€æ­¥çš„æœªè§£å†³åˆ†å­ä½œä¸º leaves
                last_stage = cumulative_route["stages"][-1] if cumulative_route["stages"] else {}
                leaves = last_stage.get("unsolved_leaves", [])
                
                # VisualizationTool.execute signature is slightly different
                # execute(self, target_smiles: str, selected_precursors: List[str], stage_number: int, output_dir: str = None)
                # Note: VisualizationTool.execute currently only visualizes ONE stage (precursors).
                # The original stage_visualize could handle cumulative_route to some extent or fallback?
                # Actually, original stage_visualize logic was simple: draw target and precursors.
                # It updated cumulative_route inline.
                
                viz_tool = VisualizationTool()
                viz_result = viz_tool.execute(
                    cumulative_route["target"], 
                    leaves, 
                    stage_number=0, 
                    output_dir=None
                )
                image_path = viz_result.get("image_path")
                image_path = viz_result.get("stage_image_path")
                print(f"  [OK] Full retrosynthesis map generated: {image_path}")
            
            # 3. å†™å…¥ Session Log
            self.session_logger.log_session_summary(cumulative_route, image_path)
            print(f"  [DONE] Session summary written: {self.session_logger.log_path}")
            
        except Exception as e:
            print(f"[FAIL] Final report generation failed: {e}")
    
    def _generate_final_report(self, status: str) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        report = {
            "status": status,
            "total_stages": len(self.history),
            "history": [h.to_dict() for h in self.history],
            "timestamp": datetime.now().isoformat(),
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(
            self.output_dir,
            f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        self._generate_markdown_report(report_path.replace(".json", ".md"), status)
        
        print(f"\n[DONE] Final Report Saved: {report_path}")
        print(f"****** FINAL REPORT: {status.upper()} ******")
        print("*" * 60)
        print(f"Final Status: {status}")
        print(f"Total Stages Processed: {len(self.history)}")
        
        return report
    
    def _generate_markdown_report(self, md_path: str, status: str):
        """ç”Ÿæˆ Markdown æ ¼å¼æŠ¥å‘Š"""
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(f"# MoleReact é€†åˆæˆè§„åˆ’æŠ¥å‘Š\n\n")
            f.write(f"- **æ—¥æœŸ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"- **çŠ¶æ€**: {status}\n")
            f.write(f"- **æ€»é˜¶æ®µæ•°**: {len(self.history)}\n")
            
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„
            md_dir = os.path.dirname(md_path)
            
            for stage_res in self.history:
                f.write(f"\n## Stage {stage_res.stage}: {stage_res.target_smiles[:40]}...\n\n")
                f.write(f"- **ç›®æ ‡**: `{stage_res.target_smiles}`\n")
                f.write(f"- **å®ŒæˆçŠ¶æ€**: {'âœ… å®Œæˆ' if stage_res.is_complete else 'â³ å¾…ç»§ç»­'}\n")
                if not stage_res.is_complete:
                    f.write(f"- **æœªè§£å†³åˆ†å­**: {len(stage_res.unsolved_leaves)}\n")
                
                # æ¨èè·¯çº¿è¡¨æ ¼
                f.write(f"\n### ğŸ† æ¨èè·¯çº¿\n")
                f.write("| æ’å | æ¥æº | å‰ä½“ | ç†ç”± |\n")
                f.write("|------|------|------|------|\n")
                
                for cand in stage_res.llm_selected_top_n:
                    rank = cand.get('rank', '-')
                    source = cand.get('source', 'unknown')
                    precursors = "<br>".join([f"`{p}`" for p in cand.get('precursors', [])])
                    reason = cand.get('reason', '').replace('\n', ' ')
                    f.write(f"| {rank} | {source} | {precursors} | {reason} |\n")
                
                # å¯è§†åŒ–å›¾ç‰‡å±•ç¤º
                if stage_res.image_paths:
                    f.write(f"\n### ğŸ“Š è·¯çº¿å¯è§†åŒ–\n")
                    f.write("| è·¯çº¿ | å¯è§†åŒ– |\n")
                    f.write("|------|--------|\n")
                    
                    for i, img_abs_path in enumerate(stage_res.image_paths):
                        try:
                            # å°è¯•è®¡ç®—ç›¸å¯¹è·¯å¾„
                            rel_path = os.path.relpath(img_abs_path, md_dir).replace("\\", "/")
                            # æ‰¾åˆ°å¯¹åº”çš„è·¯çº¿ä¿¡æ¯
                            if i < len(stage_res.llm_selected_top_n):
                                route_info = stage_res.llm_selected_top_n[i]
                                desc = f"**Route {route_info.get('rank')}**<br>Source: {route_info.get('source')}"
                            else:
                                desc = f"Route {i+1}"
                                
                            f.write(f"| {desc} | ![{desc}]({rel_path}) |\n")
                        except Exception as e:
                            f.write(f"| Route {i+1} | (å›¾ç‰‡è·¯å¾„é”™è¯¯: {e}) |\n")

                # LLM åˆ†æè¯¦æƒ… (æŠ˜å )
                if stage_res.llm_analysis:
                    f.write(f"\n<details>\n<summary>ğŸ§  LLM è¯¦ç»†åˆ†æ (ç‚¹å‡»å±•å¼€)</summary>\n\n")
                    f.write(stage_res.llm_analysis)
                    f.write(f"\n\n</details>\n")
                
                f.write(f"\n---\n")
            
        print(f"ğŸ“„ Markdown æŠ¥å‘Šå·²ä¿å­˜: {md_path}")


def main():
    parser = argparse.ArgumentParser(description="å®Œæ•´ Agent å·¥ä½œæ¨¡å—")
    parser.add_argument("--smiles", default=DEFAULT_TARGET, help="ç›®æ ‡åˆ†å­ SMILES")
    parser.add_argument("--stages", type=int, default=None, help="æœ€å¤§é˜¶æ®µæ•° (é»˜è®¤æ— é™åˆ¶)")
    parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ¨¡å¼ (ä¸äº¤äº’)")
    parser.add_argument("--no-llm", action="store_true", help="ç¦ç”¨ LLM åˆ†æ")
    parser.add_argument("--single", action="store_true", help="åªè¿è¡Œå•ä¸ªå·¥ä½œæ¨¡å—")
    
    args = parser.parse_args()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         MoleReact Agent - å®Œæ•´å·¥ä½œæ¨¡å—                            â•‘
â•‘     Complete Work Module with LLM Analysis                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    try:
        runner = CompleteWorkModuleRunner(
            use_llm=not args.no_llm,
            auto_mode=args.auto,
        )
        
        runner.initialize()
        
        if args.single:
            # åªè¿è¡Œå•ä¸ªå·¥ä½œæ¨¡å—
            result = runner.run_work_module(args.smiles, stage=1, topk=10)
            print(f"\nå®ŒæˆçŠ¶æ€: {'âœ… å¯è´­ä¹°' if result.is_complete else 'â³ å¾…ç»§ç»­'}")
        else:
            # è¿è¡Œå®Œæ•´è§„åˆ’
            report = runner.run_full_planning(args.smiles, max_stages=args.stages)
            print(f"\næœ€ç»ˆçŠ¶æ€: {report['status']}")
            print(f"æ€»é˜¶æ®µæ•°: {report['total_stages']}")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
